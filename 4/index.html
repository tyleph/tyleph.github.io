<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>CS180 Project: Neural Radiance Fields</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700&display=swap" rel="stylesheet">
    <script>
        MathJax = {
            tex: {
                inlineMath: [['$', '$'], ['\\(', '\\)']]
            }
        };
    </script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            background-color: #111827;
        }
        .header-gradient {
            background: linear-gradient(90deg, #3b82f6, #8b5cf6);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
        }
        .content-section {
            background-color: #1f2937;
        }
        code {
            background-color: #374151;
            border-radius: 0.25rem;
            padding: 0.1rem 0.3rem;
            font-family: monospace;
            color: #d1d5db;
        }
        pre > code {
            display: block;
            padding: 1rem;
            white-space: pre-wrap;
            word-wrap: break-word;
        }
    </style>
</head>
<body class="text-gray-300">

    <header class="text-center py-12 md:py-16">
        <h1 class="text-4xl md:text-5xl font-bold header-gradient mb-2">
            Neural Radiance Fields (NeRF)
        </h1>
    </header>

    <main class="container mx-auto px-6 pb-16">
        <div class="space-y-16">

            <section class="max-w-5xl mx-auto">
                <h2 class="text-3xl font-bold text-white mb-6 text-center">Part 0: Camera Calibration & Capturing a 3D Scan</h2>
                <p class="text-lg leading-relaxed mb-6">
                    Before training a NeRF, we need a dataset linking 2D images to cameras in world coordinates.
                </p>

                <!-- <h3 class="text-2xl font-bold text-white mb-4">Process</h3> -->
                <ul class="list-disc list-inside space-y-2 mb-8 ml-4 text-lg">
                    <li><strong>Calibration:</strong> I used an ArUco marker grid to capture 30+ images with my iPhone camera. I used OpenCV's <code>cv2.calibrateCamera</code> to get the intrinsic parameters and distortion coefficients.</li>
                    <li><strong>Pose Estimation:</strong> I placed a single ArUco tag next to my chosen object (a copy of the board game Coup). Using the known dimensions of the tag and the calibrated intrinsics, I used <code>cv2.solvePnP</code> to determine the extrinsic matrix (rotation and translation) for every image.</li>
                    <li><strong>Undistortion:</strong> Finally, I undistorted the images using <code>cv2.undistort</code> for NeRF.</li>
                </ul>

                <h3 class="text-2xl font-bold text-white mb-4">Camera Visualization</h3>
                <p class="text-lg leading-relaxed mb-6">
                    Below are the visualized camera frustums in 3D space (using Viser). The images I took form a dome around the center aruco tag, with the object next to the tag being a copy of the board game Coup.
                </p>

                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">Custom Image Example</h4>
                    <div class="flex justify-center">
                        <img src="images/coup_aruco.jpeg" alt="Coup PSNR Curve" class="rounded-md max-h-[500px]">
                    </div>
                </div>

                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="content-section rounded-lg p-4">
                        <img src="images/frustum1.png" alt="Camera Frustums View 1" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">Camera Frustums (View 1)</p>
                    </div>
                    <div class="content-section rounded-lg p-4">
                        <img src="images/frustum2.png" alt="Camera Frustums View 2" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">Camera Frustums (View 2)</p>
                    </div>
                </div>
            </section>

            <hr class="border-gray-700">

            <section class="max-w-5xl mx-auto">
                <h2 class="text-3xl font-bold text-white mb-6 text-center">Part 1: Fitting a Neural Field to a 2D Image</h2>
                <p class="text-lg leading-relaxed mb-6">
                    In this section, I trained a Multilayer Perceptron (MLP) to learn a continuous 2D function (an image) from coordinates. The network takes 2D pixel coordinates $(x, y)$ as input and outputs the RGB color value.
                </p>

                <div class="bg-gray-800 rounded-lg p-6 mb-8 border border-gray-700">
                    <h3 class="text-xl font-bold text-white mb-3">Implementation</h3>
                    <ul class="list-disc list-inside space-y-2 text-gray-300">
                        <li><strong>Positional Encoding (PE):</strong> To help the MLP learn high-frequency details, the 2D input coordinates were mapped to a higher dimensional space using sinusoidal functions up to frequency $L$.</li>
                        <li><strong>Architecture:</strong> A standard MLP with ReLU activations. The depth and width were tuned as hyperparameters.</li>
                        <li><strong>Loss & Metric:</strong> The network was trained using MSE. I visualize the performance with Peak Signal-to-Noise Ratio (PSNR) metric:
                            $$ \text{PSNR} = 10 \cdot \log_{10}\left(\frac{1}{\text{MSE}}\right) $$
                        </li>
                    </ul>
                </div>

                <h3 class="text-2xl font-bold text-white mt-10 mb-4 border-l-4 border-blue-500 pl-4">Subject 1: The Fox</h3>
                <div class="mb-6">
                     <p class="mb-2 font-semibold text-white">Hyperparameters:</p>
<pre><code class="language-python">hyperparams = [
    {'L': 5, 'width': 32},
    {'L': 5, 'width': 128},
    {'L': 15, 'width': 32},
    {'L': 15, 'width': 128}
]
learning_rate = 1e-2</code></pre>
                </div>

                <h4 class="text-xl font-bold text-white mb-4">Training Progression</h4>
                <div class="content-section rounded-lg p-4 mb-8">
                    <img src="images/fox_training_progress.png" alt="Fox Training Progress" class="rounded-md w-full">
                    <!-- <p class="text-center mt-3 font-medium text-white">Visual progression of the network learning the image over iterations</p> -->
                </div>

                <h4 class="text-xl font-bold text-white mb-4">Results</h4>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="content-section rounded-lg p-4">
                        <img src="images/fox_results.png" alt="Fox Grid Results" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">Varying L and Width</p>
                    </div>
                    <div class="content-section rounded-lg p-4">
                        <img src="images/fox_psnr.png" alt="Fox PSNR Curve" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">PSNR Training Curve</p>
                    </div>
                </div>

                <h3 class="text-2xl font-bold text-white mt-16 mb-4 border-l-4 border-purple-500 pl-4">Subject 2: Yuki (My Dog)</h3>
                <!-- <p class="text-lg leading-relaxed mb-4">
                    I repeated the process on a custom image of my dog, Yuki. I adjusted the hyperparameters to accommodate a potentially more complex texture.
                </p> -->

                <div class="mb-6">
                     <p class="mb-2 font-semibold text-white">Hyperparameters:</p>
<pre><code class="language-python">hyperparams = [
    {'L': 5, 'width': 64},
    {'L': 5, 'width': 384},
    {'L': 30, 'width': 64},
    {'L': 30, 'width': 384}
]
learning_rate = 1e-2</code></pre>
                </div>

                <h4 class="text-xl font-bold text-white mb-4">Results</h4>
                <div class="content-section rounded-lg p-4 mb-8">
                    <img src="images/yuki_training_progress.png" alt="Yuki Training Progress" class="rounded-md w-full">
                    <!-- <p class="text-center mt-3 font-medium text-white">Visual progression of the network learning the image over iterations</p> -->
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="content-section rounded-lg p-4">
                        <img src="images/yuki_results.png" alt="Yuki Grid Results" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">Varying L and Width</p>
                    </div>
                    <div class="content-section rounded-lg p-4">
                        <img src="images/yuki_psnr.png" alt="Yuki PSNR Curve" class="rounded-md w-full">
                        <p class="text-center mt-3 font-medium text-white">PSNR Training Curve</p>
                    </div>
                </div>

            </section>
            
            <div class="bg-gray-800 rounded-lg p-6 mt-12 border border-gray-700 shadow-lg">
                <h3 class="text-xl font-bold text-white mb-4">Analysis</h3>
                <div class="grid gap-6">
                    <div>
                        <h4 class="font-bold text-blue-400 mb-2">Varying Frequency and Width</h4>
                        <p class="text-sm leading-relaxed">
                            Increasing the <strong>Positional Encoding frequency (L)</strong> helped capture sharp edges and fine textures, as low L values act like a low-pass filter, resulting in blurry outputs. However, high L alone isn't enough. Increasing the <strong>network width</strong> (e.g., to 384 channels) helped capture more details and resulted in a clearer image overall. As expected, the best reconstructions have high L and high width.
                        </p>
                    </div>
                </div>
            </div>



            <hr class="border-gray-700 my-12">

            <section class="max-w-5xl mx-auto">
                <h2 class="text-3xl font-bold text-white mb-6 text-center">Part 2: Fitting a Neural Radiance Field from Multi-view Images</h2>
                <p class="text-lg leading-relaxed mb-8">
                    In this part, I implemented a full Neural Radiance Field (NeRF).
                </p>

                <h3 class="text-2xl font-bold text-white mb-4">Implementation Approach</h3>
                <div class="space-y-6 mb-12">
                    
                    <div class="content-section rounded-lg p-6">
                        <h4 class="text-xl font-bold text-blue-400 mb-2">2.1 & 2.2: Create Rays & Sampling</h4>
                        <p class="mb-3">
                            To simulate a camera, I implemented functions to transform pixel coordinates to world-space rays using the camera's intrinsic matrix ($K$) and extrinsic matrices (camera-to-world). 
                        </p>
                        <p>
                            For sampling, I split the ray into uniform bins and randomly sampled within each bin during training. This "perturbation" helps learn a more continuous representation instead of overfitting to discrete depth steps.
                        </p>
                    </div>

                    <div class="content-section rounded-lg p-6">
                        <h4 class="text-xl font-bold text-blue-400 mb-2">2.3 & 2.4: Dataloader & Network Architecture</h4>
                        <p class="mb-4">
                            My dataloader randomly samples rays from all training images. The network is a deeper MLP than Part 1. It takes <strong>3D world coordinates</strong> and the <strong>viewing direction</strong> as inputs.
                        </p>
                        <ul class="list-disc list-inside ml-4 space-y-1 mb-4 text-gray-400">
                            <li><strong>Positional Encoding:</strong> Applied to inputs (L=10 for coords, L=4 for view direction) to capture high frequencies.</li>
                            <li><strong>Density & Color:</strong> The network predicts volume density $\sigma$ (using ReLU) and RGB color (using Sigmoid).</li>
                            <li><strong>Skip Connections:</strong> The encoded input is concatenated into the middle of the network so that we don't lose the signal from initial image.</li>
                        </ul>
                        <div class="mt-4 bg-black/30 p-2 rounded-lg">
                            <img src="images/neural_net.png" alt="NeRF MLP Architecture" class="mx-auto rounded opacity-90">
                            <p class="text-center mt-2 text-sm text-gray-500">Network Architecture</p>
                        </div>
                    </div>

                    <div class="content-section rounded-lg p-6">
                        <h4 class="text-xl font-bold text-blue-400 mb-2">2.5: Volume Rendering</h4>
                        <p>
                            I implemented the discrete volume rendering equation. For a given ray, the final color is computed by integrating the color and density of samples along the ray, weighted by the probability that the ray didn't hit anything earlier.
                        </p>
                        <div class="overflow-x-auto mt-3">
                            $$ \hat{C}(\mathbf{r}) = \sum_{i=1}^{N} T_i (1 - \exp(-\sigma_i \delta_i))\mathbf{c}_i $$
                        </div>
                        <p class="mt-2 text-sm text-gray-400">I implemented this using <code>torch.cumsum</code> to calculate $T_i$.</p>
                    </div>
                </div>

                <h3 class="text-2xl font-bold text-white mb-4">Visualizations & Results</h3>
                <p class="text-lg leading-relaxed mb-8">
                    These below results are after 1200 iterations, achieving a PSNR of ~24.
                </p>

                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">Camera Rays & Samples</h4>
                    <div class="flex justify-center">
                        <img src="images/sampled_rays.png" alt="Sampled Rays Visualization" class="rounded-md max-h-[500px]">
                    </div>
                    <p class="text-center mt-3 text-gray-400 text-sm">
                        Visualization of camera poses and 100 random rays shot into the scene.
                    </p>
                </div>

                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">Validation PSNR Curve</h4>
                    <div class="flex justify-center">
                        <img src="images/lego_psnr.png" alt="PSNR Curve" class="rounded-md max-h-[500px]">
                    </div>
                </div>


                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">Training Progression</h4>
                    <div class="flex justify-center">
                        <img src="images/lego_training_progression.png" alt="Training Progression" class="rounded-md max-h-[500px]">
                    </div>
                </div>


                <div class="content-section rounded-lg p-6 border border-blue-500/30">
                    <h4 class="text-xl font-bold text-white mb-4 text-center">Final NeRF Rendering</h4>
                    <div class="flex justify-center">
                        <img src="images/lego_spiral.gif" alt="Spherical Rendering Video" class="rounded-lg shadow-2xl w-full max-w-lg">
                    </div>
                </div>

            </section>


            <hr class="border-gray-700 my-12">

            <section class="max-w-5xl mx-auto">
                <h2 class="text-3xl font-bold text-white mb-6 text-center">Part 2.6: Training on Custom Data</h2>
                <p class="text-lg leading-relaxed mb-8">
                    For the final part of the project, I trained the NeRF on my custom dataset collected in Part 0.
                </p>

                <h3 class="text-2xl font-bold text-white mb-4">Hyperparameters</h3>
                <div class="content-section rounded-lg p-6 mb-8">
                    <p class="mb-4">
                        Since the scale of my captured scene differs from the scale of the Lego truck dataset, I had to adjust the ray sampling hyperparameters. I took my images ~20-30 cm away from the center, leading to my choices for the "near" and "far" hyperparameters.
                    </p>
                    <ul class="list-disc list-inside space-y-2 text-gray-400">
                        <li><strong>Near Plane:</strong> <code>0.04</code></li>
                        <li><strong>Far Plane:</strong> <code>0.5</code></li>
                        <li><strong>Samples per Ray:</strong> <code>64</code> (for improved visual quality)</li>
                        <li><strong>Batch Size:</strong> I lowered the batch size of randomly sampled rays from <code>10000</code> to <code>4096</code> due to memory issues.</li>
                    </ul>
                </div>

                <h3 class="text-2xl font-bold text-white mb-4">Visualization & Results</h3>
                <p class="text-lg leading-relaxed mb-8">
                    These below results are after 3600 iterations, achieving a PSNR of ~22.5. You can see the board game Coup next to the Aruco tag.
                </p>


                <!-- <div class="grid grid-cols-1 md:grid-cols-2 gap-8 mb-8">
                    <div class="content-section rounded-lg p-4">
                        <h4 class="text-lg font-bold text-white mb-3 text-center">Training Loss Curve</h4>
                        <img src="images/custom_loss_curve.png" alt="Custom Object Loss Curve" class="rounded-md w-full">
                        <p class="text-center mt-3 text-gray-500 text-sm">Loss decreases as the network learns geometry.</p>
                    </div>
                    
                    <div class="content-section rounded-lg p-4">
                         <h4 class="text-lg font-bold text-white mb-3 text-center">Intermediate Renders</h4>
                        <div class="flex items-center justify-center h-full">
                            <img src="images/custom_training_progression.png" alt="Custom Object Training Progression" class="rounded-md w-full">
                        </div>
                        <p class="text-center mt-3 text-gray-500 text-sm">Visual progression during training.</p>
                    </div>
                </div>

                <div class="content-section rounded-lg p-6 border border-purple-500/30">
                    <h4 class="text-xl font-bold text-white mb-4 text-center">Novel Views (Spherical Rendering)</h4>
                    <div class="flex justify-center">
                        <img src="images/custom_spiral.gif" alt="Custom Object Spherical Rendering" class="rounded-lg shadow-2xl w-full max-w-lg">
                    </div>
                    <p class="text-center mt-4 text-gray-400">
                        The trained NeRF rendering novel views of the object from my custom dataset.
                    </p>
                </div> -->


                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">PSNR Curve</h4>
                    <div class="flex justify-center">
                        <img src="images/coup_psnr.png" alt="Coup PSNR Curve" class="rounded-md max-h-[500px]">
                    </div>
                </div>


                <div class="content-section rounded-lg p-4 mb-8">
                    <h4 class="text-lg font-bold text-white mb-3 text-center">Training Progression</h4>
                    <div class="flex justify-center">
                        <img src="images/coup_training_progression.png" alt="Coup Training Progression" class="rounded-md max-h-[500px]">
                    </div>
                </div>


                <div class="content-section rounded-lg p-6 border border-blue-500/30">
                    <h4 class="text-xl font-bold text-white mb-4 text-center">Final NeRF Rendering</h4>
                    <div class="flex justify-center">
                        <img src="images/custom_coup_orbit.gif" alt="Coup Rendering Video" class="rounded-lg shadow-2xl w-full max-w-lg">
                    </div>
                </div>

            </section>

        </div>
    </main>

    <footer class="text-center py-8 text-gray-500 text-sm">
        <p>CS180 Project 4 | Neural Radiance Fields</p>
    </footer>

</body>
</html>